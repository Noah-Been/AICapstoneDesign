# 데일리 리포트 생성 구조 (`generate_report.py`)

## 1. 개요
이 문서는 `generate_report.py` 스크립트가 어떻게 일일 데이터를 종합하여 최종 `daily_report_{date}.md` 파일을 생성하는지에 대한 구조와 로직을 설명합니다.

## 2. 입력 데이터
리포트 생성 스크립트는 특정 날짜의 스냅샷 디렉토리에서 다음과 같은 데이터들을 사용합니다.
- `topN.json`: `signals.py`가 생성한 Top 20 종목 정보
- `research/all.jsonl`: 4개 증권사에서 수집한 모든 리포트 원문
- `news_strict/{ticker}.jsonl`: Top 20 종목별 뉴스 데이터
- `blogs_strict/{ticker}.jsonl`: Top 20 종목별 블로그 데이터
- `KOSPI200.csv`, `KOSDDAQ150.csv`: 종목 코드와 회사명을 매칭하기 위한 정보

## 3. 최종 산출물
- `reports/daily_report_{YYYY-MM-DD}.md`: 4개의 섹션으로 구성된 최종 마크다운 리포트 파일

## 4. 핵심 생성 로직 (4-Step Process)
리포트는 4개의 주요 섹션을 순차적으로 생성하고, 이를 하나로 조합하여 완성됩니다. 각 섹션은 필요에 따라 다른 LLM 모델을 사용합니다.

```
[데이터 로딩]
      |
      v
[1. 증권사 리포트 전체 요약 생성] -- (gemini-2.5-pro, 1회 호출)
      |
      v
[2. Top 20 종목 리스트 생성] -- (LLM 미사용, 단순 데이터 포맷팅)
      |
      v
[3. 주요 종목 소셜 동향 생성] -- (gemini-2.0-flash, N회 호출)
      |
      v
[4. 최종 3줄 핵심 요약 생성] -- (gemini-2.5-pro, 1회 호출)
      |
      v
[최종 마크다운 파일 조합 및 저장]
```

### 4-1. 섹션 1: 증권사 리포트 전체 요약
- **모델:** `gemini-2.5-pro`
- **프로세스:**
  1. `research/all.jsonl` 파일에 있는 오늘 수집된 모든 증권사 리포트의 본문(`content`)을 하나로 묶습니다.
  2. LLM에게 이 전체 텍스트를 전달하며, 각 리포트별로 핵심 내용을 요약해달라고 요청합니다.
  3. 결과물은 마크다운 리스트 형태로 정리됩니다.
- **API 호출:** **1회**

### 4-2. 섹션 2: Top 20 종목 및 선정 신호
- **모델:** LLM 미사용
- **프로세스:**
  1. `topN.json` 파일을 읽어옵니다.
  2. 20개 종목의 순위, 이름, 종목코드, 그리고 선정 이유가 된 핵심 기술 지표(`proximity_pct`, `ret20_pct` 등)를 마크다운 목록 형식으로 단순 변환합니다.
- **API 호출:** **0회**

### 4-3. 섹션 3: 주요 종목 소셜 동향
- **모델:** `gemini-2.0-flash`
- **프로세스:**
  1. Top 20 종목 중, 관련 뉴스나 블로그 데이터가 존재하는 종목(N개)만 선별합니다.
  2. 해당 N개 종목에 대해 루프를 돕니다.
  3. 각 종목의 뉴스/블로그 제목들을 모아 LLM에게 전달하며, '최신 동향 요약'과 '투자 참고사항'을 생성해달라고 요청합니다.
- **API 호출:** **N회** (뉴스/블로그가 있는 종목 수만큼)

### 4-4. 섹션 4: 핵심 요약 (3줄)
- **모델:** `gemini-2.5-pro`
- **프로세스:**
  1. 위에서 생성된 섹션 1, 2, 3의 마크다운 결과물 전체를 하나의 텍스트로 합칩니다.
  2. 이 전체 리포트 내용을 LLM에게 전달하며, "투자자 입장에서 오늘 가장 주목해야 할 가장 중요한 정보만 3줄로 요약해줘" 라고 요청합니다.
- **API 호출:** **1회**

이러한 구조를 통해, 작업의 성격에 따라 각기 다른 LLM을 효율적으로 사용하고, 최종적으로는 일관된 형식의 고품질 리포트를 생성합니다.
